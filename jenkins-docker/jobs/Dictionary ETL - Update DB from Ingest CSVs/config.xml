<?xml version='1.1' encoding='UTF-8'?>
<project>
  <actions/>
  <description></description>
  <keepDependencies>false</keepDependencies>
  <properties>
    <com.sonyericsson.rebuild.RebuildSettings plugin="rebuild@332.va_1ee476d8f6d">
      <autoRebuild>false</autoRebuild>
      <rebuildDisabled>false</rebuildDisabled>
    </com.sonyericsson.rebuild.RebuildSettings>
    <hudson.model.ParametersDefinitionProperty>
      <parameterDefinitions>
        <hudson.model.StringParameterDefinition>
          <name>api</name>
          <description>the url for the api calls</description>
          <defaultValue>http://172.20.0.2:8086/api</defaultValue>
          <trim>false</trim>
        </hudson.model.StringParameterDefinition>
        <hudson.model.StringParameterDefinition>
          <name>datasetId</name>
          <defaultValue>phs002694</defaultValue>
          <trim>false</trim>
        </hudson.model.StringParameterDefinition>
        <hudson.model.BooleanParameterDefinition>
          <name>removeObsoleteConcepts</name>
          <description>checks concepts from ingest csv against existing dictionary entries for dataset. If a concept exists in dictionary but not in the dataset, removes that concept (primarily to guard against changing phv values in compliant studies)</description>
          <defaultValue>true</defaultValue>
        </hudson.model.BooleanParameterDefinition>
      </parameterDefinitions>
    </hudson.model.ParametersDefinitionProperty>
  </properties>
  <scm class="hudson.scm.NullSCM"/>
  <canRoam>true</canRoam>
  <disabled>false</disabled>
  <blockBuildWhenDownstreamBuilding>false</blockBuildWhenDownstreamBuilding>
  <blockBuildWhenUpstreamBuilding>false</blockBuildWhenUpstreamBuilding>
  <jdk>(System)</jdk>
  <triggers/>
  <concurrentBuild>true</concurrentBuild>
  <builders>
    <hudson.tasks.Shell>
      <command>#!/bin/bash

aws sts assume-role --duration-seconds 3600 --role-arn arn:aws:iam::736265540791:role/dbgap-etl --role-session-name &quot;s3-test&quot; &gt;assume-role-output.txt

export AWS_ACCESS_KEY_ID=$(grep AccessKeyId assume-role-output.txt | cut -d &apos;:&apos; -f 2 | sed &quot;s/[ ,\&quot;]//g&quot;)
export AWS_SECRET_ACCESS_KEY=$(grep SecretAccessKey assume-role-output.txt | cut -d &apos;:&apos; -f 2 | sed &quot;s/[ ,\&quot;]//g&quot;)
export AWS_SESSION_TOKEN=$(grep SessionToken assume-role-output.txt | cut -d &apos;:&apos; -f 2 | sed &quot;s/[ ,\&quot;]//g&quot;)
mkdir ${datasetId}
aws s3 cp s3://avillach-73-bdcatalyst-etl/newDictionary/${datasetId}/ ./${datasetId}/ --recursive

unset AWS_ACCESS_KEY_ID
unset AWS_SECRET_ACCESS_KEY
unset AWS_SESSION_TOKEN

#dataset insert
csvcut -z 10000000 -d &apos;œÜ&apos; -c 1,2,3,4 ${datasetId}/datasets.csv | csvformat -z 10000000 -D &apos;œÜ&apos; -U3 -Qüêç &gt;${datasetId}/dataset_table.csv
IFS=&apos;œÜ&apos;
#core dataset entry
while read datasetRef fullName abv desc; do
    if [[ ${datasetRef} != &apos;ref&apos; ]]; then
    	echo &quot;Creating Dataset&quot;
        #create dataset entry
        curl --retry 5 --retry-connrefused  --retry-delay 0   --show-error --silent --request PUT --data-urlencode &quot;datasetRef=${datasetRef}&quot; --data-urlencode &quot;abv=${abv}&quot; \
            --data-urlencode &quot;fullName=${fullName}&quot; --data-urlencode &quot;desc=${desc}&quot; ${api}/dataset || { echo &apos;dataset curl --retry 5 --retry-connrefused  --retry-delay 0   failed&apos; ; exit 1; }
        #create dataset facet
        echo &quot;Creating Dataset Facet&quot;
        curl --retry 5 --retry-connrefused  --retry-delay 0   --show-error --silent --request PUT --data-urlencode &quot;categoryName=dataset_id&quot; --data-urlencode &quot;name=${datasetRef}&quot; \
            --data-urlencode &quot;display=${abv} (${datasetRef})&quot; --data-urlencode &quot;desc=${fullName}&quot; --data-urlencode &quot;parentName=&quot; \
            ${api}/facet || { echo &apos;facet curl --retry 5 --retry-connrefused  --retry-delay 0   failed&apos; ; exit 1; }
    fi
done &lt;${datasetId}/dataset_table.csv

#dataset meta entry
echo &quot;Creating Dataset Meta&quot;
csvcut -z 10000000 -d &apos;œÜ&apos; -c 1,5- ${datasetId}/datasets.csv | csvformat -z 10000000 -D &apos;œÜ&apos; -U3 -Qüêç &gt;${datasetId}/dataset_meta_table.csv
export columncount=$(csvcut -d &apos;œÜ&apos; -z 10000000 -n ${datasetId}/dataset_meta_table.csv | wc -l)
for ((i = 2; i &lt; ${columncount} + 1; i++)); do
    keyname=$(csvcut -d &apos;œÜ&apos; -z 10000000 -c ${i} ${datasetId}/dataset_meta_table.csv | csvcut -d &apos;œÜ&apos; -z 10000000 -n | cut -c6-)
    echo $keyname
    csvcut -z 10000000 -d &apos;œÜ&apos; -c 1,${i} ${datasetId}/dataset_meta_table.csv | csvformat -z 10000000 -D &apos;œÜ&apos; &gt;${datasetId}/dataset_meta_column.csv
    while read datasetRef values; do
        if [[ ${datasetRef} != &apos;ref&apos; ]]; then
        	if [[ ! -z ${values} ]]; then
            	curl --retry 5 --retry-connrefused  --retry-delay 0   --show-error --silent --request PUT --data-urlencode &quot;datasetRef=${datasetRef}&quot; --data-urlencode &quot;key=${keyname}&quot; \
                	--data-urlencode &quot;values=${values}&quot; ${api}/dataset/metadata || { echo &apos;dataset meta curl --retry 5 --retry-connrefused  --retry-delay 0   failed&apos; ; exit 1; }
            fi
        fi
    done &lt;${datasetId}/dataset_meta_column.csv
done

#consents insert
echo &quot;Creating Consents&quot;
while read datasetRef consentCode description participantCount variableCount sampleCount authz; do
    echo datasetRef $datasetRef
    echo description $description
    echo participantCount $participantCount
    if [[ ${datasetRef} != &apos;datasetRef&apos; ]]; then
        curl --retry 5 --retry-connrefused  --retry-delay 0   --show-error --silent --request PUT --data-urlencode &quot;datasetRef=${datasetRef}&quot; --data-urlencode &quot;consentCode=${consentCode}&quot; \
            --data-urlencode &quot;description=${description}&quot; --data-urlencode &quot;authz=${authz}&quot; \
            --data-urlencode &quot;participantCount=${participantCount}&quot; --data-urlencode &quot;variableCount=${variableCount}&quot; --data-urlencode &quot;sampleCount=${sampleCount}&quot; \
            ${api}/consent || { echo &apos;consent curl --retry 5 --retry-connrefused  --retry-delay 0   failed&apos; ; exit 1; }
    fi
done &lt;${datasetId}/consents.csv

#concept insert
echo &quot;Creating Concepts&quot;
csvcut -z 10000000 -d &apos;œÜ&apos; -c 1,2,3,4,5,6 ${datasetId}/concepts.csv | csvformat -u0 -U3 -Qüêç -z 10000000 -D &apos;œÜ&apos; &gt;${datasetId}/concept_table.csv
#core concept entry
while read datasetRef name display conceptType conceptPath parentPath; do
    if [[ ${datasetRef} != &apos;datasetRef&apos; ]]; then
    	if [[ ${parentPath} != &apos;//global_variables//&apos; ]]; then     
        #add concept
        echo datasetRef $datasetRef name $name
        curl --retry 5 --retry-connrefused  --retry-delay 0   --show-error --silent --request PUT --data-urlencode &quot;datasetRef=${datasetRef}&quot; --data-urlencode &quot;name=${name}&quot; \
            --data-urlencode &quot;display=${display}&quot; --data-urlencode &quot;conceptType=${conceptType}&quot; \
            --data-urlencode &quot;conceptPath=${conceptPath}&quot; --data-urlencode &quot;parentPath=${parentPath}&quot; \
            ${api}/concept | jq -r &apos;.conceptNodeId&apos; &gt;&gt; ${datasetId}/concept_node_ids.txt
        #connect concept to dataset facet
        curl --retry 5 --retry-connrefused  --retry-delay 0   --show-error --silent --request PUT --data-urlencode &quot;facetName=${datasetRef}&quot; --data-urlencode &quot;conceptPath=${conceptPath}&quot; ${api}/facet/concept || { echo &apos;concept facet curl --retry 5 --retry-connrefused  --retry-delay 0   failed&apos; ; exit 1; }
        #connect concept to data type facet
        curl --retry 5 --retry-connrefused  --retry-delay 0   --show-error --silent --request PUT --data-urlencode &quot;facetName=${conceptType}&quot; --data-urlencode &quot;conceptPath=${conceptPath}&quot; ${api}/facet/concept || { echo &apos;concept facet curl --retry 5 --retry-connrefused  --retry-delay 0   failed&apos; ; exit 1; }
    	fi
    fi
done &lt;${datasetId}/concept_table.csv
#checks id list from ingest against existing dictionary entries for dataset. If a concept exists in dictionary but not in the dataset, removes that concept
if [[ $removeObsoleteConcepts ]]; then
	csvcut ${datasetId}/concept_node_ids.txt &gt; ${datasetId}/current_concept_nodes.txt
	curl --retry 5 --retry-connrefused  --retry-delay 0   --show-error --silent --request DELETE --header &apos;Content-Type: text/plain&apos; \
    --data-binary @${datasetId}/current_concept_nodes.txt &quot;${api}/concept/obsolete?datasetRef=${datasetId}&quot; || { echo &apos;remove obsolete vars curl --retry 5 --retry-connrefused  --retry-delay 0   failed&apos; ; exit 1; }
fi

#concept meta entry
echo &quot;Creating Concept Meta&quot;
csvcut -d &apos;œÜ&apos; -z 10000000 -c 5,7- ${datasetId}/concepts.csv | csvformat -u0 -U3 -Qüêç -z 10000000 -D &apos;œÜ&apos; &gt;${datasetId}/concept_meta_table.csv
export columncount=$(csvcut -d &apos;œÜ&apos; -z 10000000 -n ${datasetId}/concept_meta_table.csv | wc -l)
for ((i = 2; i &lt; ${columncount} + 1; i++)); do
    keyname=$(csvcut -d &apos;œÜ&apos; -z 10000000 -c ${i} ${datasetId}/concept_meta_table.csv | csvcut -z 10000000 -n | cut -c6-)
    csvcut -d &apos;œÜ&apos; -z 10000000 -c 1,${i} ${datasetId}/concept_meta_table.csv | csvformat -u0 -U3 -Qüêç -z 10000000 -D &apos;œÜ&apos; &gt;${datasetId}/concept_meta_column.csv
    while read conceptPath values; do
        if [[ ${conceptPath} != &apos;conceptPath&apos; ]]; then
        	if [[ ! -z ${values} ]]; then
            	export encodedConceptPath=$(echo -n $conceptPath | jq -sRr @uri)
            	export encodedKeyName=$(echo -n $keyname | jq -sRr @uri)
            	echo $values &gt; ${datasetId}/concept_meta_values.txt
            	curl --retry 5 --retry-connrefused  --retry-delay 0   --show-error --silent --request PUT --header &apos;Content-Type: text/plain&apos; \
                	--data @${datasetId}/concept_meta_values.txt &quot;${api}/concept/metadata?conceptPath=${encodedConceptPath}&amp;key=${encodedKeyName}&quot; || { echo &apos;concept meta curl --retry 5 --retry-connrefused  --retry-delay 0   failed&apos; ; exit 1; }
        	fi
        fi
    done &lt;${datasetId}/concept_meta_column.csv
done</command>
      <configuredLocalRules/>
    </hudson.tasks.Shell>
  </builders>
  <publishers/>
  <buildWrappers>
    <hudson.plugins.ws__cleanup.PreBuildCleanup plugin="ws-cleanup@0.47">
      <deleteDirs>false</deleteDirs>
      <cleanupParameter></cleanupParameter>
      <externalDelete></externalDelete>
      <disableDeferredWipeout>false</disableDeferredWipeout>
    </hudson.plugins.ws__cleanup.PreBuildCleanup>
  </buildWrappers>
</project>