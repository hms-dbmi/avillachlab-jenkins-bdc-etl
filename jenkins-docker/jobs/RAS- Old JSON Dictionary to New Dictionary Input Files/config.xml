<?xml version='1.1' encoding='UTF-8'?>
<project>
  <actions/>
  <description></description>
  <keepDependencies>false</keepDependencies>
  <properties>
    <com.sonyericsson.rebuild.RebuildSettings plugin="rebuild@332.va_1ee476d8f6d">
      <autoRebuild>false</autoRebuild>
      <rebuildDisabled>false</rebuildDisabled>
    </com.sonyericsson.rebuild.RebuildSettings>
    <hudson.model.ParametersDefinitionProperty>
      <parameterDefinitions>
        <hudson.model.FileParameterDefinition>
          <name>managed_inputs.tsv</name>
        </hudson.model.FileParameterDefinition>
        <hudson.model.FileParameterDefinition>
          <name>dictionary.json</name>
        </hudson.model.FileParameterDefinition>
        <hudson.model.FileParameterDefinition>
          <name>metadata.json</name>
        </hudson.model.FileParameterDefinition>
      </parameterDefinitions>
    </hudson.model.ParametersDefinitionProperty>
  </properties>
  <scm class="hudson.plugins.git.GitSCM" plugin="git@5.3.0">
    <configVersion>2</configVersion>
    <userRemoteConfigs>
      <hudson.plugins.git.UserRemoteConfig>
        <url>https://github.com/hms-dbmi/ETL-MissionControl-dbgap-submodule.git</url>
      </hudson.plugins.git.UserRemoteConfig>
    </userRemoteConfigs>
    <branches>
      <hudson.plugins.git.BranchSpec>
        <name>*/master</name>
      </hudson.plugins.git.BranchSpec>
    </branches>
    <doGenerateSubmoduleConfigurations>false</doGenerateSubmoduleConfigurations>
    <submoduleCfg class="empty-list"/>
    <extensions/>
  </scm>
  <canRoam>true</canRoam>
  <disabled>false</disabled>
  <blockBuildWhenDownstreamBuilding>false</blockBuildWhenDownstreamBuilding>
  <blockBuildWhenUpstreamBuilding>false</blockBuildWhenUpstreamBuilding>
  <jdk>(System)</jdk>
  <triggers/>
  <concurrentBuild>false</concurrentBuild>
  <builders>
    <hudson.tasks.Shell>
      <command>#!/bin/bash
mkdir oldData

mv metadata.json oldData/metadata.json
mv dictionary.json oldData/dictionary.json
mv managed_inputs.tsv oldData/managed_inputs.tsv

csvcut -t -c 1,2,4,5,8,9,10,11,13,14,16,18,19,20 oldData/managed_inputs.tsv | csvformat -z 10000000 -D &apos;Ï†&apos; &gt; inputs.csv
IFS=&apos;Ï†&apos;
[ ! -f inputs.csv ]
while read study_abv study_id study_name data_type data_ready data_processed study_focus study_design version phase additional_info_html additional_info additional_info_link study_link
do
  if [[ &quot;${data_ready,,}&quot; == &quot;yes&quot; ]] &amp;&amp; [[ &quot;${data_processed,,}&quot; == &quot;no&quot; ]]; then
	mkdir ${study_id}
    mkdir ${study_id}/output
    echo &apos;refÏ†full_nameÏ†abbreviationÏ†descriptionÏ†data_typeÏ†study_focusÏ†study_designÏ†versionÏ†phaseÏ†additional_informationÏ†additional_info_linkÏ†additional_infoÏ†study_accessionÏ†study_link&apos; &gt;&gt; ${study_id}/output/datasets.csv
	echo &quot;${study_id}Ï†${study_name}Ï†${study_abv}Ï†Ï†${data_type}Ï†${study_focus}Ï†${study_design}Ï†${version}Ï†${phase}Ï†${additional_info_html}Ï†${additional_info}Ï†${additional_info_link}Ï†${study_id}.${version}.${phase}Ï†${study_link}&quot; &gt;&gt; ${study_id}/output/datasets.csv
	jq &apos;with_entries(select(.key | contains(&quot;&apos;${study_id}&apos;&quot;)))&apos; oldData/dictionary.json &gt; ${study_id}/subset_dictionary.json
	jq &apos;[.bio_data_catalyst[] | select(.&quot;study_identifier&quot;==&quot;&apos;${study_id}&apos;&quot;)]&apos; oldData/metadata.json &gt; ${study_id}/subset_metadata.json

	java -jar jars/NewDictionaryConverter.jar --subsetDir &quot;./${study_id}/&quot;
    #do not touch the snake it breaks without the snake just trust me here
    csvformat -t -u0 -U3 -QğŸ -z 10000000 -D &apos;Ï†&apos; ./${study_id}/concepts.tsv &gt;${study_id}/output/concepts.csv
	csvformat -t -z 10000000 -D &apos;Ï†&apos; ./${study_id}/consents.tsv &gt; ${study_id}/output/consents.csv
    
    aws sts assume-role --duration-seconds 3600 --role-arn arn:aws:iam::736265540791:role/dbgap-etl --role-session-name &quot;s3-test&quot; &gt; assume-role-output.txt
	export AWS_ACCESS_KEY_ID=`grep AccessKeyId assume-role-output.txt | cut -d &apos;:&apos; -f 2 | sed &quot;s/[ ,\&quot;]//g&quot;`
	export AWS_SECRET_ACCESS_KEY=`grep SecretAccessKey assume-role-output.txt | cut -d &apos;:&apos; -f 2 | sed &quot;s/[ ,\&quot;]//g&quot;`
	export AWS_SESSION_TOKEN=`grep SessionToken assume-role-output.txt | cut -d &apos;:&apos; -f 2 | sed &quot;s/[ ,\&quot;]//g&quot;`
		aws s3 cp ./${study_id}/output/ s3://avillach-73-bdcatalyst-etl/newDictionary/RAS/${study_id}/ --recursive --exclude &apos;*&apos; --include &apos;*.csv&apos;
	unset AWS_ACCESS_KEY_ID
	unset AWS_SECRET_ACCESS_KEY
	unset AWS_SESSION_TOKEN
  fi
done  &lt; inputs.csv

</command>
      <configuredLocalRules/>
    </hudson.tasks.Shell>
  </builders>
  <publishers/>
  <buildWrappers>
    <hudson.plugins.ws__cleanup.PreBuildCleanup plugin="ws-cleanup@0.46">
      <deleteDirs>false</deleteDirs>
      <cleanupParameter></cleanupParameter>
      <externalDelete></externalDelete>
      <disableDeferredWipeout>false</disableDeferredWipeout>
    </hudson.plugins.ws__cleanup.PreBuildCleanup>
  </buildWrappers>
</project>