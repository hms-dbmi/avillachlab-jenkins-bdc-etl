<?xml version='1.1' encoding='UTF-8'?>
<project>
  <actions/>
  <description>Utilizes the genomic managed input file to create index files for each study/consent pair marked as annotated and ready for processing and not yet processed/ingested. Studies must go through FULL PIPELINE including HPDS javabin generation before completing this step to ensure all consents are built correctly and merged</description>
  <keepDependencies>false</keepDependencies>
  <properties>
    <hudson.model.ParametersDefinitionProperty>
      <parameterDefinitions>
        <hudson.model.StringParameterDefinition>
          <name>genomic_managed_inputs</name>
          <description>
</description>
          <defaultValue>s3://avillach-73-bdcatalyst-etl/general/resources/Genomic_Managed_Inputs.csv</defaultValue>
          <trim>false</trim>
        </hudson.model.StringParameterDefinition>
      </parameterDefinitions>
    </hudson.model.ParametersDefinitionProperty>
  </properties>
  <scm class="hudson.plugins.git.GitSCM" plugin="git@5.2.1">
    <configVersion>2</configVersion>
    <userRemoteConfigs>
      <hudson.plugins.git.UserRemoteConfig>
        <url>https://github.com/hms-dbmi/ETL-MissionControl-dbgap-submodule</url>
      </hudson.plugins.git.UserRemoteConfig>
    </userRemoteConfigs>
    <branches>
      <hudson.plugins.git.BranchSpec>
        <name>*/genomicIngestion</name>
      </hudson.plugins.git.BranchSpec>
    </branches>
    <doGenerateSubmoduleConfigurations>false</doGenerateSubmoduleConfigurations>
    <submoduleCfg class="empty-list"/>
    <extensions/>
  </scm>
  <canRoam>true</canRoam>
  <disabled>false</disabled>
  <blockBuildWhenDownstreamBuilding>false</blockBuildWhenDownstreamBuilding>
  <blockBuildWhenUpstreamBuilding>false</blockBuildWhenUpstreamBuilding>
  <triggers/>
  <concurrentBuild>false</concurrentBuild>
  <builders>
    <hudson.tasks.Shell>
      <command>#!/bin/bash

### assume etl role
aws sts assume-role --duration-seconds 900 --role-arn arn:aws:iam::736265540791:role/dbgap-etl --role-session-name &quot;s3-test&quot; &gt; assume-role-output.txt

export AWS_ACCESS_KEY_ID=`grep AccessKeyId assume-role-output.txt | cut -d &apos;:&apos; -f 2 | sed &quot;s/[ ,\&quot;]//g&quot;`
export AWS_SECRET_ACCESS_KEY=`grep SecretAccessKey assume-role-output.txt | cut -d &apos;:&apos; -f 2 | sed &quot;s/[ ,\&quot;]//g&quot;`
export AWS_SESSION_TOKEN=`grep SessionToken assume-role-output.txt | cut -d &apos;:&apos; -f 2 | sed &quot;s/[ ,\&quot;]//g&quot;`

mkdir data
mkdir completed
mkdir hierarchies
mkdir processing

find data/ -type f -exec rm -rf {} \;
find processing/ -type f -exec rm -rf {} \;
find completed/ -type f -exec rm -rf {} \;
rm -rf pic-sure-hpds/

aws s3 cp ${genomic_managed_inputs} data/
aws s3 cp s3://avillach-73-bdcatalyst-etl/general/completed/GLOBAL_allConcepts_merged.csv data/GLOBAL_allConcepts_merged.csv

unset AWS_ACCESS_KEY_ID
unset AWS_SECRET_ACCESS_KEY
unset AWS_SESSION_TOKEN

csvcut -c 1,2,3,4,5,7,8,9 data/Genomic_Managed_Inputs.csv &gt; genomic_inputs.csv

cat data/Genomic_Managed_Inputs.csv

cat	genomic_inputs.csv

IFS=&apos;,&apos;
[ ! -f inputs.csv ]
while read abv_name stdy_id stdy_consent stdy_anno stdy_proc stdy_acc stdy_samp stdy_subj
do
	if [[ &quot;${stdy_anno,,}&quot; == &quot;yes&quot; ]]; then
    	if [[ &quot;${stdy_proc,,}&quot; == &quot;no&quot; ]]; then
    		echo &quot;$stdy_id $stdy_consent ready to process, fetching subject and sample multi files and patient mapping&quot;
            
            aws sts assume-role --role-arn arn:aws:iam::${stdy_acc}:role/nih-nhlbi-TopMed-EC2Access-S3 --role-session-name &quot;get-multi-files&quot; &gt; assume-role-output.txt
			export AWS_ACCESS_KEY_ID=`grep AccessKeyId assume-role-output.txt | cut -d &apos;:&apos; -f 2 | sed &quot;s/[ ,\&quot;]//g&quot;`
			export AWS_SECRET_ACCESS_KEY=`grep SecretAccessKey assume-role-output.txt | cut -d &apos;:&apos; -f 2 | sed &quot;s/[ ,\&quot;]//g&quot;`
			export AWS_SESSION_TOKEN=`grep SessionToken assume-role-output.txt | cut -d &apos;:&apos; -f 2 | sed &quot;s/[ ,\&quot;]//g&quot;`
            aws s3 cp ${stdy_samp} data/${stdy_id}.sample.multi.txt.gz
            aws s3 cp ${stdy_subj} data/${stdy_id}.subject.multi.txt.gz
            gzip -d -f data/${stdy_id}.sample.multi.txt.gz || mv data/${stdy_id}.sample.multi.txt.gz data/${stdy_id}.sample.multi.txt
            gzip -d -f data/${stdy_id}.subject.multi.txt.gz || mv data/${stdy_id}.subject.multi.txt.gz data/${stdy_id}.subject.multi.txt
            rm -f data/${stdy_id}.sample.multi.txt.gz
            rm -f data/${stdy_id}.subject.multi.txt.gz
        	unset AWS_ACCESS_KEY_ID
			unset AWS_SECRET_ACCESS_KEY
			unset AWS_SESSION_TOKEN
            
            aws sts assume-role --duration-seconds 900 --role-arn arn:aws:iam::736265540791:role/dbgap-etl --role-session-name &quot;get-patient-mapping&quot; &gt; assume-role-output.txt
			export AWS_ACCESS_KEY_ID=`grep AccessKeyId assume-role-output.txt | cut -d &apos;:&apos; -f 2 | sed &quot;s/[ ,\&quot;]//g&quot;`
			export AWS_SECRET_ACCESS_KEY=`grep SecretAccessKey assume-role-output.txt | cut -d &apos;:&apos; -f 2 | sed &quot;s/[ ,\&quot;]//g&quot;`
			export AWS_SESSION_TOKEN=`grep SessionToken assume-role-output.txt | cut -d &apos;:&apos; -f 2 | sed &quot;s/[ ,\&quot;]//g&quot;`
            aws s3 cp s3://avillach-73-bdcatalyst-etl/${abv_name,,}/data/${abv_name^^}_PatientMapping.v2.csv data/
            unset AWS_ACCESS_KEY_ID
			unset AWS_SECRET_ACCESS_KEY
			unset AWS_SESSION_TOKEN
        fi
    fi
done &lt; genomic_inputs.csv

java -jar jars/SampleIdGenerator.jar
aws s3 cp completed/ s3://avillach-biodatacatalyst-deployments-3drb48r/genomic-etl/ingestion-indexes/ --recursive --exclude &quot;*.csv&quot;</command>
      <configuredLocalRules/>
    </hudson.tasks.Shell>
  </builders>
  <publishers/>
  <buildWrappers>
    <hudson.plugins.ws__cleanup.PreBuildCleanup plugin="ws-cleanup@0.45">
      <deleteDirs>false</deleteDirs>
      <cleanupParameter></cleanupParameter>
      <externalDelete></externalDelete>
      <disableDeferredWipeout>false</disableDeferredWipeout>
    </hudson.plugins.ws__cleanup.PreBuildCleanup>
  </buildWrappers>
</project>